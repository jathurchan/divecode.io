{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#! DO NOT ADD OR MODIFY IMPORTS - YOU NEED TO WORK WITH THE ABOVE IMPORTS !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Handling Missing Values\n",
    "\n",
    "### 1.1 What I've been told to do\n",
    "\n",
    "> Strategy :\n",
    "> - Numerical Features : Fill with median\n",
    "> - Categorical Features : fill with mode\n",
    "\n",
    "> Edge Cases to Consider :\n",
    "> - Numerical column with all NaN values: Should fill with 0 or exclude the column\n",
    "> - Categorical column with all NaN values: Should fill with 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 What I've learned to do\n",
    "\n",
    "#### Handling Missing Values in Numerical Features\n",
    "\n",
    "In the case of numerical features with all NaN values, it depends on the context of the data for the decision to fill with 0 or exclude the column.\n",
    "\n",
    "> **Example 1** : In a dataset about customer purchases, if a column represents a numerical feature (e.g., “number of luxury items bought”) but contains only NaNs, it may be better to remove it as it adds no value.\n",
    "\n",
    "> **Example 2** : In a dataset where a column represents “number of visits to a website,” and the missing values mean no visits occurred, replacing NaN with 0 makes sense.\n",
    "\n",
    "#### Handling Missing Values in Categorical Features\n",
    "\n",
    "In the case of categorical features with all NaN values, the decision to exclude or fill with 'unknown' depends on the context of the data.\n",
    "\n",
    "> **Example 1** : In a dataset about customer preferences, if a column represents a categorical feature (e.g., “favorite luxury brand”) but contains only NaN, it may be better to remove it as it adds no value.\n",
    "\n",
    "> **Example 2** : In a dataset where a column represents “preferred contact method,” and the missing values indicate no preference or unknown status, replacing NaN with 'unknown' makes sense.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Handle missing values in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with handled missing values\n",
    "    \"\"\"\n",
    "\n",
    "    # Select only numerical columns (Age, Salary, Experience)\n",
    "    numerical_cols = df.select_dtypes(include=[\"number\"])\n",
    "    \n",
    "    # Select only categorical columns (Department, Education)\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\"])\n",
    "    \n",
    "    # If all values in Age column are missing, drop the column (since 0 has a meaning in this context)\n",
    "    if df['age'].isnull().all():\n",
    "        df = df.drop(['age'])\n",
    "    else:\n",
    "        df['age'] = df['age'].fillna(df['age'].median())\n",
    "    \n",
    "    # If all values in other numerical columns except Age (Salary and Experience) are missing, fill with 0\n",
    "    # In terms of Salary, NaN means no salary, so it is reasonable to fill with 0\n",
    "    # In terms of Experience, NaN means no experience, so it is reasonable to fill with 0\n",
    "    for col in numerical_cols:\n",
    "        if col != 'age':    # True for Salary and Experience\n",
    "            if df[col].isnull().all():\n",
    "                df[col] = 0\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        # If all values in categorical columns are missing, fill with \"unknown\"\n",
    "        # In terms of Department, NaN means unknown department, so it is reasonable to fill with \"unknown\"\n",
    "        # In terms of Education, NaN means unknown education, so it is reasonable to fill with \"unknown\"\n",
    "        # We shouldn't remove the column since it has a meaning and could have non-NaN values in the future and could have an impact on the model\n",
    "        if df[col].isnull().all():\n",
    "            df[col] = \"unknown\"\n",
    "        else:\n",
    "            # Mode could be the most frequent value in the column\n",
    "            df[col] = df[col].fillna(df[col].mode(dropna=True)[0])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Remove Outliers\n",
    "\n",
    "### 2.1. What I've been told to do\n",
    "\n",
    "> - For each column in 'columns', calculate the mean and standard deviation.\n",
    "> - Compute the z-score for each value in the column.\n",
    "> - Drop rows where the z-score exceeds 'threshold'.\n",
    "\n",
    "\n",
    "```text\n",
    "Z-score calculation (pseudo-code):\n",
    "\n",
    "z_scores = (column_values - column_mean) / column_std\n",
    "Use 'np.abs(z_scores) < threshold' to filter rows.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. What I've learned to do\n",
    "\n",
    "We are doing the manual calculation of z-scores to remove outliers. However, we can use the `zscore` function from the `scipy.stats` module to calculate z-scores for each value in the column.\n",
    "\n",
    "```python\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate z-scores for each value in the column\n",
    "z_scores = zscore(df['column_name'])\n",
    "\n",
    "# Filter rows based on z-scores\n",
    "threshold = 3\n",
    "df = df[(np.abs(z_scores) < threshold)]\n",
    "```\n",
    "\n",
    "Careful: Here we consider only one column at a time. If you want to remove outliers from multiple columns, you can calculate z-scores for each column and then combine them to filter rows.\n",
    "It is shown in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df: pd.DataFrame, columns: list, threshold: float = 3\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove outliers from specified numerical columns using z-score method.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        columns: List of numerical columns to check for outliers\n",
    "        threshold: Z-score threshold (default = 3)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with outliers removed\n",
    "    \"\"\"\n",
    "    # Calculate z-scores for the specified columns (same shape as df)\n",
    "    z_scores = (df[columns] - df[columns].mean(axis=0)) / df[columns].std(axis=0)\n",
    "    \n",
    "    # Remove for each row where the absolute value of z-scores is less than the threshold\n",
    "    # for every columns in that row\n",
    "    return df[(np.abs(z_scores) < threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale Numerical Features\n",
    "\n",
    "### 3.1. What I've been told to do\n",
    "\n",
    "Scale numerical features using StandardScaler. (A bit vague)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. What I've learned to do\n",
    "\n",
    "We can use the `StandardScaler` class from the `sklearn.preprocessing` module to scale numerical features. The `StandardScaler` scales each feature to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "By default, the `StandardScaler` scales each feature (columns) independently. Same goes for `MinMaxScaler` but with a different formula.\n",
    "\n",
    "> Use StandardScaler when features have different units or scales but are approximately normally distributed.\n",
    "> Use MinMaxScaler when you need all features in the same range, especially when the data is not normally distributed or for models that are sensitive to absolute magnitude.\n",
    "\n",
    "And,\n",
    "> If you want all features scaled together (globally) based on the entire dataset, you would need to preprocess the data differently (e.g., flattening all features, calculating the global minimum and maximum, and scaling accordingly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scale numerical features using StandardScaler.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        columns: List of numerical columns to scale\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with scaled features\n",
    "    \"\"\"\n",
    "    df[columns] = scaler.fit_transform(df[columns])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Features\n",
    "\n",
    "### 4.1. What I've been told to do\n",
    "\n",
    "> 1. First fills NaN values with a placeholder to ensure consistent encoding.\n",
    "> 2. Encode categorical variables using one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. What I've learned to do\n",
    "\n",
    "We can use the `OneHotEncoder` class from the `sklearn.preprocessing` module to encode categorical features using one-hot encoding.\n",
    "\n",
    "The `OneHotEncoder` class converts categorical features into binary vectors. Each unique category value is mapped to an integer value and then converted into a binary vector with all zero values except the index of the integer, which is marked with a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Encode categorical variables using one-hot encoding.\n",
    "    First fills NaN values with a placeholder to ensure consistent encoding.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        columns: List of categorical columns to encode\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with encoded categorical variables\n",
    "    \"\"\"\n",
    "    # Replace NaN values with 'unknown'\n",
    "    df[columns] = df[columns].fillna(\"unknown\")\n",
    "    \n",
    "    # Performs one-hot encoding\n",
    "    encoded_array = encoder.fit_transform(df[columns]).toarray()\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_array, columns=encoder.get_feature_names_out(columns)\n",
    "    )\n",
    "    \n",
    "    # Drop original columns and concatenate encoded columns\n",
    "    df = pd.concat([df.drop(columns, axis=1), encoded_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame, numerical_columns: list, categorical_columns: list\n",
    "    ) -> Tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline.\n",
    "\n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        numerical_columns: List of numerical columns\n",
    "        categorical_columns: List of categorical columns\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - Preprocessed DataFrame\n",
    "        - Dictionary with preprocessing statistics\n",
    "    \"\"\"\n",
    "    # Preprocessing Steps:\n",
    "    # 1. Handle missing values (use 'handle_missing_values').\n",
    "    preprocessed_df = handle_missing_values(df)\n",
    "    # 2. Remove outliers (use 'remove_outliers').\n",
    "    preprocessed_df = remove_outliers(df, numerical_columns)\n",
    "    # 3. Scale features (use 'scale_features').\n",
    "    preprocessed_df = scale_features(df, numerical_columns)\n",
    "    # 4. Encode categorical variables (use 'encode_categorical').\n",
    "    preprocessed_df = encode_categorical(df, categorical_columns)\n",
    "    # Ensure each step is applied in the specified order.\n",
    "    # Implement full preprocessing pipeline\n",
    "    # Should return (preprocessed_df, stats_dict)\n",
    "\n",
    "    stats_dict = {}\n",
    "    for col in numerical_columns:\n",
    "        stats_dict[col] = {\n",
    "            \"mean\": preprocessed_df[col].mean(),\n",
    "            \"std\": preprocessed_df[col].std(),\n",
    "        }\n",
    "\n",
    "    return preprocessed_df, stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        age    salary  experience  department_Finance  department_HR  \\\n",
      "0  0.489727  0.916849   -0.105625                 0.0            0.0   \n",
      "1 -0.069833  0.570817    0.299068                 0.0            0.0   \n",
      "2  0.601640 -0.071815   -0.307972                 0.0            0.0   \n",
      "3  1.608849 -0.615580    0.096722                 0.0            1.0   \n",
      "4 -0.293657  0.373084   -1.319705                 0.0            0.0   \n",
      "\n",
      "   department_IT  department_Marketing  department_Sales  education_Bachelor  \\\n",
      "0            0.0                   1.0               0.0                 0.0   \n",
      "1            0.0                   1.0               0.0                 1.0   \n",
      "2            1.0                   0.0               0.0                 1.0   \n",
      "3            0.0                   0.0               0.0                 1.0   \n",
      "4            0.0                   0.0               1.0                 1.0   \n",
      "\n",
      "   education_Master  education_PhD  \n",
      "0               0.0            1.0  \n",
      "1               0.0            0.0  \n",
      "2               0.0            0.0  \n",
      "3               0.0            0.0  \n",
      "4               0.0            0.0  \n",
      "Preprocessing complete!\n",
      "\n",
      "Preprocessing statistics:\n",
      "age: {'mean': np.float64(-2.486899575160351e-16), 'std': np.float64(1.0005003753127737)}\n",
      "salary: {'mean': np.float64(-1.8474111129762604e-16), 'std': np.float64(1.0005003753127737)}\n",
      "experience: {'mean': np.float64(-6.217248937900877e-17), 'std': np.float64(1.0005003753127737)}\n"
     ]
    }
   ],
   "source": [
    "# Load sample dataset\n",
    "df = pd.read_csv(\"sample_dataset.csv\")\n",
    "\n",
    "# Define columns\n",
    "numerical_cols = [\"age\", \"salary\", \"experience\"]\n",
    "categorical_cols = [\"department\", \"education\"]\n",
    "\n",
    "# Preprocess data\n",
    "processed_df, stats = preprocess_data(\n",
    "    df.copy(), numerical_cols, categorical_cols\n",
    ")\n",
    "\n",
    "print(processed_df.head())\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(\"\\nPreprocessing statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
